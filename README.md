# Formal Logic Deduction
![deduction example](./images/deduction_example_GPT4.png)

**F**ormal **L**ogic **D**eduction (**FLD**) is a project to teach language models deductive reasoning using synthetically generated examples based on formal logic theory.
FLD project originates from the paper [Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic](https://arxiv.org/abs/2308.07336) (ICML2023).

## News
We have released a Japanese logical benchmark, **JFLD** (**Ja**panese **Fo**rmal **Lo**gic **D**eduction).
See [here](https://github.com/hitachi-nlp/FLD-corpus/blob/main/README.JFLD.md).

## What's good?
FLD serves as ...

* ğŸ‘Š **A Challenging Benchmark for Logical Reasoning**: FLD assesses (i) pure reasoning *isolated from knowledge*, and (ii) diverse reasoning patterns. Indeed, even GPT-4 can solve only about half of the problems.
* ğŸ“ **A Foundation for Learning Logical Reasoning**: The FLD corpus teaches the **fundamentals** of logic, adopting a well-grounded set of atomic deduction rules based on formal logic theory.
* ğŸš€ **A Basis for Future Experimental Studies**: It encompasses several toolkits as listed below, paving the way for innovative research.

## Contents
* You can use the corpora via ğŸ¤— huggingface hub. See [here](https://github.com/hitachi-nlp/FLD-corpus).
* You can evaluate various LLMs, such as GPT-4 and Llama, by using [lm-evlauation-harness](https://github.com/EleutherAI/lm-evaluation-harness/tree/main/lm_eval/tasks/fld) or [our evaluation scripts](https://github.com/hitachi-nlp/FLD-fewshot-ICL-eval).
* You can fine-tune language models on FLD corpora. You can either use a logical-reasoning framework [LogiTorch/logitorch](https://github.com/LogiTorch/logitorch), or [our training scripts](https://github.com/hitachi-nlp/FLD-prover/).
* You can generate corpora with your own setting using [our corpus generator](https://github.com/hitachi-nlp/FLD-generator/).

## Other materials (Japanese only)
* [æ—¥çµŒãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹2024/1æœˆå·: è¨€èªãƒ¢ãƒ‡ãƒ«ã®è«–ç†æ¨è«–èƒ½åŠ›ã‚’å¤§ããæ”¹å–„ã€æ—¥ç«‹ãŒå­¦ç¿’ç”¨ã‚³ãƒ¼ãƒ‘ã‚¹ã®è‡ªå‹•ç”ŸæˆæŠ€è¡“](https://xtech.nikkei.com/atcl/nxt/mag/rob/18/012600001/00136)
* [äººå·¥çŸ¥èƒ½å­¦ä¼š2023: äººå·¥æ¼”ç¹¹æ¨è«–ã‚³ãƒ¼ãƒ‘ã‚¹ã«ã‚ˆã‚‹å­¦ç¿’ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ã©ã®ã‚ˆã†ã«å¼·åŒ–ã™ã‚‹ã‹ï¼Ÿ](https://www.jstage.jst.go.jp/article/pjsai/JSAI2023/0/JSAI2023_2E5GS605/_pdf)
* [è¨€èªå‡¦ç†å­¦ä¼š2023: å½¢å¼è«–ç†å­¦ã«åŸºã¥ãæ¼”ç¹¹ã‚³ãƒ¼ãƒ‘ã‚¹ã«ã‚ˆã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹æ¼”ç¹¹æ¨è«–èƒ½åŠ›ã®ä»˜ä¸](https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/B1-2.pdf)

## Contact
For any reason where a GitHub pull request or an issue is not appropriate, feel free to email terufumi.morishita.wp[at]hitachi.com.

## Citation
```bibtex
@InProceedings{pmlr-v202-morishita23a,
  title = 	 {Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic},
  author =       {Morishita, Terufumi and Morio, Gaku and Yamaguchi, Atsuki and Sogawa, Yasuhiro},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {25254--25274},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/morishita23a/morishita23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/morishita23a.html},
}
```
